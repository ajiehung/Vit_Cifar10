# vit_cifar10

This example implements the Vision Transformer (ViT) model by Alexey Dosovitskiy et al. for image classification, and demonstrates it on the CIFAR-100 dataset. The ViT model applies the Transformer architecture with self-attention to sequences of image patches, without using convolution layers.

![image](https://github.com/ajiehung/vit_cifar10/blob/main/images/vit_model.png)